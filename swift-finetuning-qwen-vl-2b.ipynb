{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# install all the requirements for miniCPM-V\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install --upgrade modelscope sentencepiece accelerate bitsandbytes datamodel_code_generator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install deepspeed>=0.9.3\n","!pip install liger-kernel-nightly==0.2.1.dev20240911164559"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/modelscope/swift.git\n","%cd swift\n","!pip install -e '.[llm]'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install pyav"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install qwen_vl_utils"]},{"cell_type":"markdown","metadata":{},"source":["## QWEN-VL-2B DATASET CREATION"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create Stratified Sample to Train Data for Training VLM\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Read the CSV file\n","df = pd.read_csv('/kaggle/input/amazon-ml-train/train.csv')\n","\n","# Calculate the sample size (1% of total rows)\n","sample_size = int(len(df) * 0.01)\n","\n","# Perform stratified sampling\n","stratified_sample, _ = train_test_split(\n","    df,\n","    test_size=1 - (sample_size / len(df)),\n","    stratify=df['entity_name'],\n","    random_state=42  # for reproducibility\n",")\n","\n","# Verify the sample size\n","print(f\"Original dataset size: {len(df)}\")\n","print(f\"Sampled dataset size: {len(stratified_sample)}\")\n","\n","# Verify the distribution\n","print(\"\\nOriginal distribution:\")\n","print(df['entity_name'].value_counts(normalize=True))\n","print(\"\\nSampled distribution:\")\n","print(stratified_sample['entity_name'].value_counts(normalize=True))\n","\n","# Save the sampled dataset\n","stratified_sample.to_csv('/kaggle/working/sample_train.csv', index=False)\n","print(\"\\nSampled dataset saved as 'sample_train.csv'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# download images\n","import os\n","from time import time\n","import multiprocessing\n","import logging\n","import requests\n","import pandas as pd\n","import time as t\n","import random \n","\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","img_dir = 'image_dir'\n","\n","def get_sbu_urls():\n","    df = pd.read_csv('/kaggle/working/sample_train.csv')\n","    urls = df['image_link'].tolist()\n","    indices = df.index\n","    return list(zip(indices, urls))\n","\n","def scrape_and_save(args):\n","    url, savepath = args\n","    retries = 3\n","    for attempt in range(retries):\n","        try:\n","            session = requests.Session()\n","            response = session.get(url, timeout=1)\n","            response.raise_for_status()\n","            with open(savepath, 'wb') as f:\n","                f.write(response.content)\n","            logging.info(f\"Successfully downloaded: {url}\")\n","            return True\n","        except requests.RequestException as e:\n","            logging.error(f\"Error downloading {url}: {e} (Attempt {attempt+1}/{retries})\")\n","        except IOError as e:\n","            logging.error(f\"Error saving file {savepath}: {e}\")\n","            return False\n","        t.sleep(2)  # small delay before retrying\n","    return False\n","\n","if __name__ == '__main__':\n","    startidx = 0\n","    chunk_size = 5000  # Break downloads into chunks\n","    urls = get_sbu_urls()\n","    total_urls = len(urls)\n","\n","    if not os.path.exists(img_dir):\n","        os.makedirs(img_dir)\n","\n","    starttime = time()\n","    piccounter = 0\n","\n","    # Download in chunks\n","    for chunk_start in range(startidx, total_urls, chunk_size):\n","        chunk_end = min(chunk_start + chunk_size, total_urls)\n","        url_chunk = urls[chunk_start:chunk_end]\n","        \n","        pool = multiprocessing.Pool(16)  # create a new pool for each chunk\n","\n","        results = []\n","        for i, (index, url) in enumerate(url_chunk, start=chunk_start):\n","            name = f'train_{index}.jpg'\n","            savepath = os.path.join(img_dir, name)\n","            result = pool.apply_async(scrape_and_save, ((url, savepath),))\n","            results.append(result)\n","\n","        pool.close()  # no more tasks\n","        pool.join()  # wait for completion\n","\n","        # Count successful downloads in the chunk\n","        successful_downloads = sum([r.get() for r in results])\n","        piccounter += successful_downloads\n","\n","        logging.info(f\"Downloaded {successful_downloads}/{chunk_size} in chunk {chunk_start//chunk_size + 1}. Total downloaded: {piccounter}/{total_urls}\")\n","\n","        # Throttle requests to prevent server throttling (optional)\n","        t.sleep(10)  # 10-second break between chunks\n","\n","    print(f\"Downloaded {piccounter}/{total_urls} images.\")\n","    print(f\"Total time taken: {time() - starttime:.2f} seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","\n","entity_unit_map = {\n","    'depth': ['mm',\"'\",'cm','centimetre', 'millimetre', 'inch', 'metre', 'foot'],\n","    'height': ['centimetre', 'millimetre', 'inch', 'metre', 'foot'],\n","    'width': ['millimetre', 'centimetre', 'inch', 'foot', 'metre'],\n","    'item_volume': ['cup', 'gallon', 'ounce', 'millilitre', 'cubic foot', 'fluid ounce', 'decilitre', 'cubic inch', 'litre', 'quart', 'pint', 'centilitre'],\n","    'item_weight': ['gram', 'milligram', 'kilogram', 'kilogram to kilogram', 'ounce', 'pound', 'ton', 'microgram', 'millilitre', 'gigabyte', 'gram to gram', 'kilogram to ilogram', 'candela', 'fluid ounce', 'ounce to ounce', 'pound to pound', 'cup', 'milligram to milligram', 'carat', 'litre', 'e pound', 'nits', 'inch', 'quart', 'watt', 'millimetre', 'centimetre', 'millilitre to millilitre', 'cubic inch'],\n","    'maximum_weight_recommendation': ['kilogram', 'pound', 'ounce', 'ton', 'milligram', 'kilogram to kilogram', 'gram', 'microgram', 'person', 'pound to pound', 'pound to ound', 'foot', 'kilogram to ilogram', 'horsepower'],\n","    'voltage': ['volt'],\n","    'wattage': ['watt', 'horsepower', 'kilowatt', 'kilowatt hour', 'milliampere hour']\n","}\n","\n","\n","def prepare_dataset(csv_path, image_dir, output_json_path, question, answer_column):\n","    # Read the CSV file\n","    df = pd.read_csv(csv_path)\n","    \n","    # Prepare the data in the required format\n","    data = []\n","    for index, row in df.iterrows():\n","        image_path = os.path.join(image_dir, f\"train_{index}.jpg\")\n","        \n","        # Check if the image file exists\n","        if not os.path.exists(image_path):\n","            print(f\"Warning: Image file not found for index {index}\")\n","            continue\n","        \n","        entry = {\n","            \"system\": f\"You are an entity extractor OCR model. Given the entity, you can extract the text from the image denoting the entity value. Entity value is always a number followed by its unit like {entity_unit_map[row['entity_name']]}.\",\n","            \"query\": f\"<image>What is the value of the {row['entity_name']} of the item shown? Give me numerical value and unit as seen in the image. Example Input: What is the value of the volume of the item shown, Output : 1 cup. Adhere to instructions.\",\n","            \"response\": f\"{row['entity_value'].split()}\",\n","            \"images\": [f\"{image_path}\"]\n","        }\n","        data.append(entry)\n","    \n","    # Write the data to a JSON file\n","    with open(output_json_path, 'w') as f:\n","        json.dump(data, f, indent=2)\n","    \n","    print(f\"Dataset prepared and saved to {output_json_path}\")\n","\n","# Usage\n","csv_path = '/kaggle/working/sample_train.csv'\n","image_dir = '/kaggle/working/image_dir/'\n","output_json_path = '/kaggle/working/train.json'\n","\n","prepare_dataset(csv_path, image_dir, output_json_path, question, answer_column)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!SIZE_FACTOR=8 MAX_PIXELS=313600 CUDA_VISIBLE_DEVICES=0,1 swift sft \\\n","    --model_type qwen2-vl-2b-instruct \\\n","    --model_id_or_path qwen/Qwen2-VL-2B-Instruct \\\n","    --sft_type lora \\\n","    --dataset /kaggle/working/train.json \\\n","    --freeze_vit \\\n","    --seed 42 \\\n","    --max_length 128 \\\n","    --lora_rank 32 \\\n","    --use_liger \\\n","    --num_train_epochs 1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r checkpoint163.zip /kaggle/working/output/qwen2-vl-2b-instruct/v3-20240914-130231/checkpoint-163/"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls -lah"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5694652,"sourceId":9385819,"sourceType":"datasetVersion"},{"datasetId":5694787,"sourceId":9385993,"sourceType":"datasetVersion"},{"datasetId":5702884,"sourceId":9396232,"sourceType":"datasetVersion"},{"datasetId":5698110,"sourceId":9396765,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
